(window.webpackJsonp=window.webpackJsonp||[]).push([[80],{616:function(v,_,s){"use strict";s.r(_);var t=s(7),e=Object(t.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h1",{attrs:{id:"redis"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis"}},[v._v("#")]),v._v(" Redis")]),v._v(" "),_("hr"),v._v(" "),_("h2",{attrs:{id:"什么是redis"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#什么是redis"}},[v._v("#")]),v._v(" 什么是redis")]),v._v(" "),_("p",[v._v("redis是一款基于内存的k-v数据结构的非关系型数据库，读写速度非常快，常用于"),_("strong",[v._v("缓存，消息队列、分布式锁等场景")]),v._v("。")]),v._v(" "),_("h3",{attrs:{id:"redis的数据类型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis的数据类型"}},[v._v("#")]),v._v(" redis的数据类型")]),v._v(" "),_("p",[v._v("string：字符串   缓存对象，token，session，数字自增，分布式锁")]),v._v(" "),_("p",[v._v("list：列表   消息队列")]),v._v(" "),_("p",[v._v("hash：哈希   缓存对象 购物车")]),v._v(" "),_("p",[v._v("set：集合  缓存对象  点赞可能认识的人，共同好友。社交功能  收藏夹")]),v._v(" "),_("p",[v._v("zset：有序集合   排行榜")]),v._v(" "),_("p",[v._v("geo：地理  地理位置附近的人，滴滴")]),v._v(" "),_("p",[v._v("hyperloglog：基数统计 网站pu统计")]),v._v(" "),_("p",[v._v("stream：流  消息队列")]),v._v(" "),_("p",[v._v("bitmap：位图  登录状态，连续签到，二值统计")]),v._v(" "),_("p",[v._v("Redis还支持事务，发布-订阅，切片集群，主从复制，哨兵，持久化，内存淘汰机制，lua脚本，过期删除策略")]),v._v(" "),_("h2",{attrs:{id:"为什么使用redis作为mysql的缓存"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用redis作为mysql的缓存"}},[v._v("#")]),v._v(" 为什么使用redis作为mysql的缓存")]),v._v(" "),_("p",[v._v("高性能")]),v._v(" "),_("p",[v._v("高并发")]),v._v(" "),_("h2",{attrs:{id:"常见数据类型的底层实现"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#常见数据类型的底层实现"}},[v._v("#")]),v._v(" 常见数据类型的底层实现")]),v._v(" "),_("table",[_("thead",[_("tr",[_("th",[v._v("数据类型")]),v._v(" "),_("th",[v._v("3.0")]),v._v(" "),_("th",[v._v("7.0")])])]),v._v(" "),_("tbody",[_("tr",[_("td",[v._v("string")]),v._v(" "),_("td",[v._v("SDS")]),v._v(" "),_("td",[v._v("SDS")])]),v._v(" "),_("tr",[_("td",[v._v("list")]),v._v(" "),_("td",[v._v("双向链表，压缩列表")]),v._v(" "),_("td",[v._v("quicklist")])]),v._v(" "),_("tr",[_("td",[v._v("hash")]),v._v(" "),_("td",[v._v("压缩列表，哈希表")]),v._v(" "),_("td",[v._v("listpack，哈希表")])]),v._v(" "),_("tr",[_("td",[v._v("set")]),v._v(" "),_("td",[v._v("哈希表，整数集合")]),v._v(" "),_("td",[v._v("哈希表，整数集合")])]),v._v(" "),_("tr",[_("td",[v._v("zset")]),v._v(" "),_("td",[v._v("压缩列表，跳表")]),v._v(" "),_("td",[v._v("listpack，跳表")])])])]),v._v(" "),_("p",[v._v("元素数量小于512，元素长度小于64字节")]),v._v(" "),_("p",[v._v("string：简单动态字符串")]),v._v(" "),_("p",[v._v("list：quicklist（压缩列表，双向链表）")]),v._v(" "),_("p",[v._v("hash：listpack（压缩列表，哈希表）")]),v._v(" "),_("p",[v._v("set：元素少于512个且为整数，整数集合；否则哈希表")]),v._v(" "),_("p",[v._v("zset：元素小于128，元素值小于64字节时压缩列表；否则跳表")]),v._v(" "),_("p",[v._v("7.0后压缩列表又listpack代替")]),v._v(" "),_("h2",{attrs:{id:"redis线程模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis线程模型"}},[v._v("#")]),v._v(" Redis线程模型")]),v._v(" "),_("hr"),v._v(" "),_("h3",{attrs:{id:"redis是单线程吗"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis是单线程吗"}},[v._v("#")]),v._v(" redis是单线程吗")]),v._v(" "),_("p",[v._v("先指出什么是redis的单线程：redis的单线程指的是接受客户端请求，解析请求，处理请求，进行数据读写操作，发送请求结果是由主线程处理的")]),v._v(" "),_("p",[v._v("然后分析redis程序不是单线程：启动redis程序，不仅由主线程还有后台线程，关闭处理文件，aof刷盘，lazyfree线程（异步释放内存）")]),v._v(" "),_("h3",{attrs:{id:"redis采用单线程为什么还那么快"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis采用单线程为什么还那么快"}},[v._v("#")]),v._v(" redis采用单线程为什么还那么快")]),v._v(" "),_("p",[v._v("redis内存操作")]),v._v(" "),_("p",[v._v("I/O多路复用机制")]),v._v(" "),_("p",[v._v("单线程模型，避免多线程频繁的创建和切换")]),v._v(" "),_("h3",{attrs:{id:"redis之前为什么是单线程模型"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis之前为什么是单线程模型"}},[v._v("#")]),v._v(" redis之前为什么是单线程模型")]),v._v(" "),_("p",[v._v("一方面：redis性能瓶颈不在于cpu，而在于网络IO，多线程也仅仅是处理网络IO时使用多线程，指令处理过程还是单线程。\n另一方面：多线程频繁的创建销毁和切换也是不小的cpu开销，增加了系统复杂性，还需要考虑加锁场景。aaaaaa")]),v._v(" "),_("h2",{attrs:{id:"redis持久化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis持久化"}},[v._v("#")]),v._v(" Redis持久化")]),v._v(" "),_("p",[v._v("==AOF日志：==执行完一条写命令，就将命令追加到server.aof_biuf缓冲区，然后通过系统write（）调用将aof_buf缓冲区的数据写入到aof文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区page_cache,等待内核将数据写入磁盘。在，redis重启时，会读取aof文件中的命令，进行数据恢复。")]),v._v(" "),_("p",[v._v("这个过程是先执行命令再去存储命令：一方面避免了对命令的语法检查，另一方面不会阻塞写命令运行；但是可能会发生数据丢失和阻塞后续命令")]),v._v(" "),_("p",[v._v("AOF写回策略有三种：")]),v._v(" "),_("p",[v._v("alway：立即写回磁盘")]),v._v(" "),_("p",[v._v("severysec：每秒写入一次")]),v._v(" "),_("p",[v._v("no：有内核控制写入时机")]),v._v(" "),_("table",[_("thead",[_("tr",[_("th",[v._v("写回策略")]),v._v(" "),_("th",[v._v("写回时机")]),v._v(" "),_("th",[v._v("优点")]),v._v(" "),_("th",[v._v("缺点")])])]),v._v(" "),_("tbody",[_("tr",[_("td",[v._v("always")]),v._v(" "),_("td",[v._v("立即写回")]),v._v(" "),_("td",[v._v("可靠性高，几乎不会丢失数据")]),v._v(" "),_("td",[v._v("磁盘压力大，性能开销大")])]),v._v(" "),_("tr",[_("td",[v._v("everysec")]),v._v(" "),_("td",[v._v("每秒写回")]),v._v(" "),_("td",[v._v("性能适中")]),v._v(" "),_("td",[v._v("宕机时最多损失1s内数据")])]),v._v(" "),_("tr",[_("td",[v._v("no")]),v._v(" "),_("td",[v._v("内核决定")]),v._v(" "),_("td",[v._v("性能好")]),v._v(" "),_("td",[v._v("宕机时可能损失最多数据")])])])]),v._v(" "),_("p",[v._v("AOF日志过大时会触发AOF重写：读取当前数据库中所有的键值对，记录到新的aof文件，从后将文件重命名替换原来的aof文件，先生成后替换模式避免了源文件发生污染。")]),v._v(" "),_("p",[v._v("重写AOF过程是由后台子进程bgrewriteaof完成的：1.避免了主进程阻塞，主进程可能继续处理请求 2.使用主进程而不是主线程，多线程之间会共享内存，修改共享内存数据时需要加锁来保证数据安全。而父子进程是以只读方式共享内存数据的，当一方发生写操作时就会触发写时复制，形成两个独立数据副本就不用加锁来保证数据安全")]),v._v(" "),_("p",[v._v("如果AOF日志重写过程中主线程处理了写请求，那么写请求命令会被同时写进AOF缓冲区和AOF重写缓冲区，当子进程完成AOF重写后，主进程会将AOF重写缓冲区的所有内容追加到新的AOF文件中，改名覆盖原来文件。")]),v._v(" "),_("p",[v._v("==RDB快照==：记录某一个瞬间的内存数据。这种方法重启时恢复数据比AOF重启快得多。AOF重启是将命令重新执行一遍，速度非常慢")]),v._v(" "),_("p",[v._v("RDB快照又save和bgsave两个命令控制。")]),v._v(" "),_("p",[v._v("save：主线程进行RDB快照生成，会阻塞主线程")]),v._v(" "),_("p",[v._v("bgsave：创建一个子进程来处理生成RDB文件")]),v._v(" "),_("p",[v._v("Redis 的快照是"),_("strong",[v._v("全量快照")]),v._v("，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多")]),v._v(" "),_("p",[v._v("RDB执行快照的时候，数据还是可以被修改的，写时复制技术。执行bgsave命令时会fork一个子进程，会将主线程的页表复制一份给子进程，这两份页表指向同一片内存区域，当一方尝试进行写操作时就会触发写时复制，创建两个独立的数据副本，RDB快照继续对副本进行快照，主线程又可以进行写命令操作。")]),v._v(" "),_("p",[v._v("==混合持久化==：RDB快照重启时恢复快，但是宕机会损失较多数据；AOF重启式恢复较慢，但是宕机时损失数据较少。这样既保证了重启数据恢复速度又降低了数据丢失风险。")]),v._v(" "),_("p",[v._v("混合持久化工作在AOF日志重写的过程中，当执行aof日志重写时，主进程fork的子进程就会先将与主进程共享的数据以RDB快照的形式存入aof文件，然后主进程记录在aof重写缓冲区的数据会以aof日志的形式追加到aof文件，这样就形成了一个混合持久化文件，然后替换原来的aof文件。这样重启时会先加载保存大量数据的rdb文件，然后加载较少的aof文件，使得重启数据恢复数据较快。因为原来的一部分命令以快照的形式存储了起来。这个重启是指数据全部加载完毕，因为rdb里面的key可能被修改，入药aof文件进行修正，这样才算重启全部完成。")]),v._v(" "),_("table",[_("thead",[_("tr",[_("th",[v._v("持久化方式")]),v._v(" "),_("th",[v._v("数据")]),v._v(" "),_("th",[v._v("重启")])])]),v._v(" "),_("tbody",[_("tr",[_("td",[v._v("AOF")]),v._v(" "),_("td",[v._v("宕机数据丢失少")]),v._v(" "),_("td",[v._v("重启数据恢复较慢")])]),v._v(" "),_("tr",[_("td",[v._v("RDB")]),v._v(" "),_("td",[v._v("宕机丢失数据较多")]),v._v(" "),_("td",[v._v("重启数据恢复快")])]),v._v(" "),_("tr",[_("td",[v._v("混合持久化")]),v._v(" "),_("td",[v._v("宕机数据丢失较少")]),v._v(" "),_("td",[v._v("重启数据较快")])])])]),v._v(" "),_("h2",{attrs:{id:"redis如何实现高可用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis如何实现高可用"}},[v._v("#")]),v._v(" Redis如何实现高可用")]),v._v(" "),_("p",[v._v("主从复制")]),v._v(" "),_("p",[v._v("主从复制就是将一台redis服务器同步数据到多台从服务器，就是一主多从的模式，并且主从服务器之间采用读写分离的模式。")]),v._v(" "),_("p",[v._v("主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，从服务器一般只读，并接受主服务器同步的写操作命令。")]),v._v(" "),_("p",[v._v("所有的写操作都是由主服务器完成的，主从服务器的数据是一致的，无法保证强一致性。在从节点进行写操作会报错，因为从节点默认是只读模式")]),v._v(" "),_("p",[v._v("哨兵模式")]),v._v(" "),_("p",[v._v("哨兵模式是为了解决Redis主从模式主服务器宕机时需要手动恢复的问题，哨兵模式可以监控主从服务器，并提供主从节点故障转移功能。")]),v._v(" "),_("p",[v._v("切片集群")]),v._v(" "),_("p",[v._v("当redis缓存数据达到一台服务器无法缓存的时候，就需要使用redis切片集群方案。将数据散发到不同的服务器上。")]),v._v(" "),_("p",[v._v("Redis Cluster采用hash槽来处理数据与节点之间的映射关系。一个切片集群共有16384个hash槽。")]),v._v(" "),_("p",[v._v("具体过程发了为两步：")]),v._v(" "),_("ul",[_("li",[v._v("根据键值对的 key，按照 "),_("a",{attrs:{href:"https://en.wikipedia.org/wiki/Cyclic_redundancy_check",target:"_blank",rel:"noopener noreferrer"}},[v._v("CRC16 算法 "),_("OutboundLink")],1),v._v("计算一个 16 bit 的值。")]),v._v(" "),_("li",[v._v("再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。")])]),v._v(" "),_("p",[v._v("具体映射方案：")]),v._v(" "),_("ul",[_("li",[_("strong",[v._v("平均分配：")]),v._v(" 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。")]),v._v(" "),_("li",[_("strong",[v._v("手动分配：")]),v._v(" 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。")])]),v._v(" "),_("h2",{attrs:{id:"集群脑裂导致数据丢失问题"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#集群脑裂导致数据丢失问题"}},[v._v("#")]),v._v(" 集群脑裂导致数据丢失问题")]),v._v(" "),_("p",[v._v("主从架构中，主节点与所有从节点因为网络波动失去联系，但与客户端依旧保持连接，客户端依旧向这个主节点写数据，但是这些数据无法同步给从节点，哨兵发现主节点失联重新选举主节点，这样一个集群就出现了两个主节点。当原来主节点重连时，会降级为从节点，并且清空数据与主节点进行数据同步。那么失联那段时间写入的数据就会丢失。")]),v._v(" "),_("p",[v._v("解决方案：当主节点下线或者通信时间超时的总数量小于阈值的时候，紧张主节点写入数据，客户端返回错误。")]),v._v(" "),_("p",[v._v("min-slaves-to-write 主节点至少需要与几个节点连接，小于这个数禁止写数据")]),v._v(" "),_("p",[v._v("min-slaves-max-lag  主从数据复制和同步延迟不能超过多少秒，超时就会禁止写入数据")]),v._v(" "),_("p",[v._v("即使原主库是假故障，期间也无法响应哨兵心跳和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了。")]),v._v(" "),_("p",[v._v("等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。")]),v._v(" "),_("h2",{attrs:{id:"redis过期删除和内存淘汰策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis过期删除和内存淘汰策略"}},[v._v("#")]),v._v(" Redis过期删除和内存淘汰策略")]),v._v(" "),_("p",[v._v("如果key设置了过期时间就会把key带上过期时间存入到过期字典中。")]),v._v(" "),_("p",[v._v("过期删除：惰性删除，定时删除，定期删除  ，redis使用定期删除和惰性删除结合的策略。")]),v._v(" "),_("p",[v._v("定时删除：顶个计数器，到期自动删除")]),v._v(" "),_("p",[v._v("惰性删除：等查询到key时去判断是否过期")]),v._v(" "),_("p",[v._v("定期删除：过一段时间随机抽取20个键，如果超过五个就会再抽取20个，执行时间有一个阈值默认是25ms")]),v._v(" "),_("table",[_("thead",[_("tr",[_("th",[v._v("过期删除策略")]),v._v(" "),_("th",[v._v("优点")]),v._v(" "),_("th",[v._v("缺点")])])]),v._v(" "),_("tbody",[_("tr",[_("td",[v._v("定时删除")]),v._v(" "),_("td",[v._v("能及时清理过期键值")]),v._v(" "),_("td",[v._v("会占用大量的cpu资源")])]),v._v(" "),_("tr",[_("td",[v._v("惰性删除")]),v._v(" "),_("td",[v._v("占用很少的系统资源，对cpu时间最友好")]),v._v(" "),_("td",[v._v("key不被访问一直存在，造成内存浪费")])]),v._v(" "),_("tr",[_("td",[v._v("定期删除")]),v._v(" "),_("td",[v._v("限制执行时长和频率，削减对cpu的占用，减少了过期🗡的内存消耗")]),v._v(" "),_("td",[v._v("难以去确定执行的时长和频率")])])])]),v._v(" "),_("h2",{attrs:{id:"redis持久化时会对过期🗡做什么处理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis持久化时会对过期🗡做什么处理"}},[v._v("#")]),v._v(" Redis持久化时会对过期🗡做什么处理")]),v._v(" "),_("p",[v._v("RDB文件生成阶段：RDB文件生成期间会对key进行检查，过期的🗡不会被保存到新的RDB文件中。\nRDB文件加载阶段：主服务器：会对🗡进行检查，过期键不会被加载到内存中；从服务器：接收到主服务器的RDB文件不会对键的状态进行检查，从节点在执行只读操作时，如果是有expire设定的key，则会根据自己机器上的时钟来判断是否已过期，如果未过期，则返回给客户端。但从节点本身不执行删除操作，而是会等待后面的del同步操作。")]),v._v(" "),_("p",[v._v("AOF重写阶段：会对键值进行过期检查，过期的不会被保留到新生成的aof文件  （aof文件过大）\nAOF写入阶段：如果过期键没被删除，aof文件会保留此过期键，当过期间被删除后，会向aof文件显式追加一条删除命令    (生成aof)")]),v._v(" "),_("h2",{attrs:{id:"redis主从复制时-对过期键如何处理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis主从复制时-对过期键如何处理"}},[v._v("#")]),v._v(" Redis主从复制时，对过期键如何处理")]),v._v(" "),_("p",[v._v("只有主服务器进行过期扫描，从库过期键依靠主服务器控制，主服务器会向AOF文件追加del命令，同步到从库。")]),v._v(" "),_("h2",{attrs:{id:"redis内存满了会发生什么"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis内存满了会发生什么"}},[v._v("#")]),v._v(" Redis内存满了会发生什么")]),v._v(" "),_("p",[v._v("就会触发内存淘汰机制")]),v._v(" "),_("p",[v._v("不做数据淘汰：满了就无法进行写操作命令，但是可以执行删除查询等操作 。maxmemory可以设置最大运行内存")]),v._v(" "),_("p",[v._v("执行数据淘汰：")]),v._v(" "),_("p",[v._v("1.对过期时间中数据进行淘汰：volatile-random,volatile-ttl,volatile-lru,volatile-lfu")]),v._v(" "),_("p",[v._v("2.对所有键进行数据淘汰: allkeys-random,allkeys-lru,allkeys-lfu")]),v._v(" "),_("h2",{attrs:{id:"lru-算法和-lfu-算法有什么区别"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#lru-算法和-lfu-算法有什么区别"}},[v._v("#")]),v._v(" LRU 算法和 LFU 算法有什么区别？")]),v._v(" "),_("p",[v._v("传统的LRU算法基于链表实现，链表中的元素按照操作顺序从前往后排列，最新操作的元素会一道链表头部，删除末尾元素。")]),v._v(" "),_("p",[v._v("redis没有采用传统的方法，因为这样需要维护一个链表，会带来额外的空间开销，并且存储数据非常多的时候链表会很大，大量访问时就会产生很多移动操作，极大的耗费性能。")]),v._v(" "),_("p",[v._v("redis在对象头中添加了一个24位的lru字段用于记录最后一次访问的时间，随机淘汰时就是比较这个时间来决定是否淘汰，这样就不用维护链表节省了空间，提高了效率和性能。但是当一次性读取大量的数据，而这些数据只会被读取一次，却能保存相当长的时间，造成缓存污染。")]),v._v(" "),_("p",[v._v("LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题。")]),v._v(" "),_("p",[v._v("redis在对象头中添加一个24位的lfu字段，高16位用来记录上次访问的时间戳ldt，低八位用来记录拼凑logc，这个是按数学概率来进行增加削减的。")]),v._v(" "),_("h2",{attrs:{id:"redis缓存设计"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis缓存设计"}},[v._v("#")]),v._v(" Redis缓存设计")]),v._v(" "),_("h3",{attrs:{id:"如何避免缓存雪崩-缓存击穿-缓存穿透"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何避免缓存雪崩-缓存击穿-缓存穿透"}},[v._v("#")]),v._v(" 如何避免缓存雪崩，缓存击穿，缓存穿透")]),v._v(" "),_("p",[v._v("缓存雪崩：过期时间更加均匀，比如给过期时间加上随机数值；不设置过期时间，由后台服务决定更新时机")]),v._v(" "),_("p",[v._v("缓存击穿：设置互斥锁，如双重检查锁；不设置过期时间，有后台决定更新时机；进行限流，一次只允许几个请求")]),v._v(" "),_("p",[v._v("缓存穿透：对于空请求返回一个默认值；使用布隆过滤器；限制非法请求。")]),v._v(" "),_("h3",{attrs:{id:"redis缓存是策略-动态缓存热点数据"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis缓存是策略-动态缓存热点数据"}},[v._v("#")]),v._v(" Redis缓存是策略，动态缓存热点数据")]),v._v(" "),_("p",[v._v("数据存储受限，系统并不是将所有的数据都添加到缓存中，而只是将其中一部分热点数据缓存起来。")]),v._v(" "),_("p",[v._v("动态热点缓存的策略是：根据数据最新访问时间来进行排名，并过滤到不常用的数据，只留下经常访问的数据。")]),v._v(" "),_("p",[v._v("在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。")]),v._v(" "),_("h3",{attrs:{id:"常见的缓存更新策略"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#常见的缓存更新策略"}},[v._v("#")]),v._v(" 常见的缓存更新策略")]),v._v(" "),_("p",[v._v("Write Back：写回策略")]),v._v(" "),_("p",[v._v("Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。")]),v._v(" "),_("p",[v._v("redis没有异步更新数据库的功能")]),v._v(" "),_("p",[v._v("常用在计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存")]),v._v(" "),_("p",[v._v("Cache Aside：旁路缓存策略")]),v._v(" "),_("p",[v._v("写：更新数据库数据，然后更新缓存数据")]),v._v(" "),_("p",[v._v("读：如果缓存命中，直接返回数据；缓存不在就去数据库查找，然后更新缓存")]),v._v(" "),_("p",[v._v("不能先删除缓存再更新数据库：会出现缓存和数据库数据不一致性的问题")]),v._v(" "),_("p",[v._v("适合读多写少的场景。")]),v._v(" "),_("p",[v._v("Write /  Read Through：写穿读穿策略")]),v._v(" "),_("p",[v._v("read through：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。")]),v._v(" "),_("p",[v._v("write through：当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：")]),v._v(" "),_("ul",[_("li",[v._v("如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。")]),v._v(" "),_("li",[v._v("如果缓存中数据不存在，直接更新数据库，然后返回；")])]),v._v(" "),_("p",[v._v("本地缓存可以这种策略；分布式缓存无法实现，因为没有此类功能")]),v._v(" "),_("h2",{attrs:{id:"redis如何实现延迟队列"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis如何实现延迟队列"}},[v._v("#")]),v._v(" Redis如何实现延迟队列")]),v._v(" "),_("p",[v._v("使用场景：")]),v._v(" "),_("ol",[_("li",[v._v("订单超时未支付自动关闭")]),v._v(" "),_("li",[v._v("外卖十分钟没有接单会自动取消")])]),v._v(" "),_("p",[v._v("Redis可以使用有序集合ZSet来实现延迟消息队列，ZSet的score属性可以赋值给延迟执行的时间，轮询比对利用arangebyscore来查询所有待处理任务，循环执行即可")]),v._v(" "),_("h2",{attrs:{id:"redis的大key问题如何处理"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis的大key问题如何处理"}},[v._v("#")]),v._v(" Redis的大Key问题如何处理")]),v._v(" "),_("p",[v._v("大key：")]),v._v(" "),_("p",[v._v("String类型的值大于10kb")]),v._v(" "),_("p",[v._v("Hash，List，Set，ZSet类型元素超过5000个")]),v._v(" "),_("p",[v._v("大key带来的问题：")]),v._v(" "),_("ol",[_("li",[v._v("操作大key比较耗时，客户端阻塞，可能响应超时")]),v._v(" "),_("li",[v._v("获取大key产生的流量较大，可能引发网络阻塞")]),v._v(" "),_("li",[v._v("del删除大key引发主线程阻塞")]),v._v(" "),_("li",[v._v("集群模型在slot分片均匀的情况下会产生数据和查询倾斜的问题，部分大key的几点内存占用多，QPS也比较大")])]),v._v(" "),_("p",[v._v("如何找到大key")]),v._v(" "),_("ol",[_("li",[_("p",[v._v('redis-cli   -a "密码"  --bigkeys   从节点或者小流量时期，该检测会阻塞主线程 ； 方法只会返回bigest key无法返回前n个数据；集合类型 只会统计menber数量，不会计算占用大小。')])]),v._v(" "),_("li",[_("p",[v._v("scan 命令  scan是基于游标的迭代器，scan命令对数据库扫描，然后type获取类型，根据不同类型使用不同命令来获取长度")]),v._v(" "),_("p",[v._v("string:  STRLEN来获取字符串长度\n集合类型：MEMORY USAGE来查询")])]),v._v(" "),_("li",[_("p",[v._v("RdbTools工具\nRdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key\nrdb dump.rdb -c memory --bytes 10240 -f redis.csv")])])]),v._v(" "),_("p",[v._v("如何删除大key\n不能直接删除大key：在应用程序释放内存时，==操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配==。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。")]),v._v(" "),_("p",[v._v("分批删除大Key：删除大 Hash，使用 "),_("code",[v._v("hscan")]),v._v(" 命令，每次获取 100 个字段，再用 "),_("code",[v._v("hdel")]),v._v(" 命令，每次删除 1 个字段。\n删除大 List，通过 "),_("code",[v._v("ltrim")]),v._v(" 命令，每次删除少量元素。\n删除大 Set，使用 "),_("code",[v._v("sscan")]),v._v(" 命令，每次扫描集合中 100 个元素，再用 "),_("code",[v._v("srem")]),v._v(" 命令每次删除一个键。\n删除大 ZSet，使用 "),_("code",[v._v("zremrangebyrank")]),v._v(" 命令，每次删除 top 100个元素。\n异步删除：用 unlink 命令代替 del 来删除, Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。")]),v._v(" "),_("h2",{attrs:{id:"redis管道有什么作用"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis管道有什么作用"}},[v._v("#")]),v._v(" redis管道有什么作用")]),v._v(" "),_("p",[v._v("管道技术可以解决多个命令执行时的网络等待，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞。")]),v._v(" "),_("p",[v._v("管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。")]),v._v(" "),_("h2",{attrs:{id:"redis支持事务回滚吗"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#redis支持事务回滚吗"}},[v._v("#")]),v._v(" Redis支持事务回滚吗？")]),v._v(" "),_("p",[v._v("Redis 中并没有提供回滚机制，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，已经执行过的命令结果也不会删除，起不到回滚的效果。")]),v._v(" "),_("h2",{attrs:{id:"如何使用redis实现分布式锁"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#如何使用redis实现分布式锁"}},[v._v("#")]),v._v(" 如何使用redis实现分布式锁")]),v._v(" "),_("p",[v._v("分布式锁用于控制分布式场景下某一个资源只能被某一个应用所使用。\nRedis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：")]),v._v(" "),_("p",[v._v("Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件")]),v._v(" "),_("ul",[_("li",[v._v("加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；")]),v._v(" "),_("li",[v._v("锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；")]),v._v(" "),_("li",[v._v("锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；")])]),v._v(" "),_("div",{staticClass:"language-java line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-java"}},[_("code",[_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("SET")]),v._v(" lock_key unique_value "),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("NX")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token constant"}},[v._v("PX")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("10000")]),v._v(" \n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br")])]),_("p",[v._v("解锁的过程就是将 lock_key 键删除（del lock_key），要保证执行操作的客户端就是加锁的客户端。\n解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。")]),v._v(" "),_("p",[v._v("解锁是有两个操作，需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。")]),v._v(" "),_("div",{staticClass:"language-lua line-numbers-mode"},[_("pre",{pre:!0,attrs:{class:"language-lua"}},[_("code",[_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("if")]),v._v(" redis"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("call")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),_("span",{pre:!0,attrs:{class:"token string"}},[v._v('"get"')]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(",")]),v._v("KEY"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token operator"}},[v._v("==")]),v._v(" ARGV"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("then")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("return")]),v._v(" redis"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),_("span",{pre:!0,attrs:{class:"token function"}},[v._v("call")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),_("span",{pre:!0,attrs:{class:"token string"}},[v._v('"del"')]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(",")]),v._v("KEYS"),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),_("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("else")]),v._v("\n    "),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("return")]),v._v(" "),_("span",{pre:!0,attrs:{class:"token number"}},[v._v("0")]),v._v("\n"),_("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("end")]),v._v("\n")])]),v._v(" "),_("div",{staticClass:"line-numbers-wrapper"},[_("span",{staticClass:"line-number"},[v._v("1")]),_("br"),_("span",{staticClass:"line-number"},[v._v("2")]),_("br"),_("span",{staticClass:"line-number"},[v._v("3")]),_("br"),_("span",{staticClass:"line-number"},[v._v("4")]),_("br"),_("span",{staticClass:"line-number"},[v._v("5")]),_("br")])]),_("p",[v._v("基于rediss的分布式锁优点：")]),v._v(" "),_("ol",[_("li",[v._v("性能高效")]),v._v(" "),_("li",[v._v("redis本身提供了setnx方法，实现简单")]),v._v(" "),_("li",[v._v("redis可以集群部署，能够避免单点故障")])]),v._v(" "),_("p",[v._v("缺点：")]),v._v(" "),_("ol",[_("li",[v._v("超时时间不好设置。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。看门狗机制去自动续约。")]),v._v(" "),_("li",[v._v("Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性。主节点获取到锁后还没同步就宕机了，新的主节点还能获取到锁。就失效了")])]),v._v(" "),_("p",[v._v("分布式锁算法 Redlock（红锁）：是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。这种算法对于集群设备之间的时序和系统时钟苛刻要求。")]),v._v(" "),_("ul",[_("li",[v._v("有界网络延迟（可以保证数据包始终在某个保证的最大值内到达 延迟），")]),v._v(" "),_("li",[v._v("有界进程暂停（换句话说，硬实时约束，通常只有 在汽车安全气囊系统等中找到），以及")]),v._v(" "),_("li",[v._v("有界时钟错误")])]),v._v(" "),_("p",[v._v("系统 有 5 个 Redis 节点（A、B、C、D 和 E）和 2 个客户端（1 和 2）。如果时钟在一个上会发生什么 的 Redis 节点向前跳跃？")]),v._v(" "),_("ol",[_("li",[_("p",[v._v("客户端 1 在节点 A、B、C 上获得锁定，由于网络问题，无法访问 D 和 E。")])]),v._v(" "),_("li",[_("p",[v._v("节点 C 上的时钟向前跳跃，导致锁过期。")])]),v._v(" "),_("li",[_("p",[v._v("客户端 2 在节点 C、D、E 上获得锁定，由于网络问题，无法访问 A 和 B。")])]),v._v(" "),_("li",[_("p",[v._v("客户端 1 和 2 现在都认为他们掌握着锁。")])]),v._v(" "),_("li",[_("p",[v._v("客户端 1 请求锁定节点 A、B、C、D、E。")])]),v._v(" "),_("li",[_("p",[v._v("当对客户端 1 的响应在传输中时，客户端 1 进入停止世界的 GC。")])]),v._v(" "),_("li",[_("p",[v._v("所有 Redis 节点上的锁都会过期。")])]),v._v(" "),_("li",[_("p",[v._v("客户端 2 在节点 A、B、C、D、E 上获得锁定。")])]),v._v(" "),_("li",[_("p",[v._v("客户端 1 完成 GC，并收到来自 Redis 节点的响应，指示其成功 获取了锁（当进程 暂停）。")])]),v._v(" "),_("li",[_("p",[v._v("客户端 1 和 2 现在都认为他们掌握着锁。")])])]),v._v(" "),_("p",[_("a",{attrs:{href:"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html",target:"_blank",rel:"noopener noreferrer"}},[v._v("如何进行分布式锁定 — Martin Kleppmann 的博客"),_("OutboundLink")],1)])])}),[],!1,null,null,null);_.default=e.exports}}]);